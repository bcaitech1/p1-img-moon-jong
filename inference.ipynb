{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "combined-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opt.ml.Dataset import ImageDataset\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "confidential-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = torch.load('./opt/ml/checkpoints/F1CE_additional/checkpoint_at_7_additional_F1CE.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "affecting-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from opt.ml.models import Resnet34, Resnext50, Resnet101, Resnet101_8class\n",
    "\n",
    "model = Resnet101_8class(num_classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "raised-accreditation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(check['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "wicked-radiation",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./opt/ml/learned_models/agefilter_F1CE_state_dict.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "developmental-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "previous-basis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d865c73f7fc84827be9cd47c3c480f4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test inference is done!\n"
     ]
    }
   ],
   "source": [
    "#submissiona 데이터와 이미지 경로를 불러옵니다.\n",
    "submission = pd.read_csv('./input/data/eval/info.csv')\n",
    "test_path = './input/data/eval/images/'\n",
    "test_data_path = [os.path.join(test_path, img) for img in submission.ImageID]\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    Resize((224, 224)),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.2, 0.2, 0.2))\n",
    "\n",
    "])\n",
    "\n",
    "test_dataset = TestDataset(test_data_path, \n",
    "                           transform= test_transform)\n",
    "\n",
    "test_data_loader = DataLoader(test_dataset,\n",
    "                         shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 모델을 정의합니다. (학습한 모델이 있다면 torch.load로 모델을 불러주세요!)\n",
    "device = torch.device('cuda')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "indexing_dict = {'gender': [0, 3],\n",
    "                 'age': [0, 1, 2],\n",
    "                 'mask':[0, 6, 12]}\n",
    "\n",
    "# 모델이 테스트 데이터셋을 예측하고 결과를 저장합니다.\n",
    "all_predictions = []\n",
    "for batch_images in tqdm(test_data_loader):\n",
    "    with torch.no_grad():\n",
    "        images = batch_images.to(device)\n",
    "        pred = model(images)\n",
    "        age = pred[0][:2].argmax()\n",
    "        gender = pred[0][2:5].argmax()\n",
    "        mask = pred[0][5:].argmax()\n",
    "        \n",
    "        classified = (indexing_dict['gender'][int(age.cpu())] + \n",
    "                     indexing_dict['age'][int(gender.cpu())] + \n",
    "                     indexing_dict['mask'][int(mask.cpu())])\n",
    "\n",
    "\n",
    "#         pred = pred.argmax(dim=-1)\n",
    "#         classified = pred.cpu().numpy()[0]\n",
    "        all_predictions.append(classified)\n",
    "submission['ans'] = all_predictions\n",
    "\n",
    "# 제출할 파일을 저장합니다.\n",
    "submission.to_csv('prediction_csv/CEadditional_7_epochs.csv', index=False)\n",
    "print('test inference is done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "available-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "df_list = []\n",
    "for i, df in enumerate(glob('./candidate/*.csv')):\n",
    "    df_list.append(pd.read_csv(df))\n",
    "    df_list[i].columns = ['ImageID', i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "northern-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pred = df_list[0]\n",
    "\n",
    "for df in df_list[1:]:\n",
    "    all_pred = pd.merge(all_pred, df, how= 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "general-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "ensemble = []\n",
    "for values in all_pred.values:\n",
    "    ensemble.append(mode(values[1:])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "radio-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['ans'] = pd.Series(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "horizontal-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('prediction_csv/ensemble.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-portfolio",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
